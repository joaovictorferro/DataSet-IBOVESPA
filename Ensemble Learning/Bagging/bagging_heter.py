# -*- coding: utf-8 -*-
"""Bagging_heter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    XXXX

# Imports
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

from sklearn.metrics import mean_squared_error
from sklearn.metrics import explained_variance_score
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_log_error
from sklearn.metrics import r2_score
import time

from sklearn.neural_network import MLPRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor

df = pd.read_csv("XXXX")

"""# Division Train and Test"""

X = df.drop(['Close'],axis=1)
Y = df['Close']

# division Train and Test
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)

"""# Dict Models"""

base_regression = [('dt', DecisionTreeRegressor(criterion= 'friedman_mse', max_depth = 4)),
                   ('svr', SVR(C= 1, epsilon = 0.1, gamma = 'auto', kernel = 'rbf')),
                   ('mlpl', MLPRegressor(activation= 'identity', batch_size= 32, hidden_layer_sizes= (34), learning_rate = 'constant', solver= 'adam')),
                  ]

"""# Bootstrapping"""

time_init = time.time()

import numpy as np

# Set the number of estimators
n_estimators = 1

# Initialize an empty dictionary to store the individual models
individual_models = {name: [] for name, _ in base_regression}

# Create multiple individual models for each base classifier using bootstraping
for clf_name, clf in base_regression:
    for i in range(n_estimators):
        # Create a training set with bootstrap
        indices = np.random.choice(len(x_train), size=len(x_train), replace=True)
        X_bootstrapped, y_bootstrapped = x_train.iloc[indices], y_train.iloc[indices]

        # Create a new model and train it on the bootstraped training set
        new_clf = clf
        new_clf.fit(X_bootstrapped, y_bootstrapped)

        # Add the template to the individual template list
        individual_models[clf_name].append(new_clf)

"""# Aggregation"""

predictions = {reg_name: np.zeros((x_test.shape[0], n_estimators)) for reg_name, _ in base_regression}
for reg_name, reg_list in individual_models.items():
    for i, reg in enumerate(reg_list):
          predictions[reg_name][:, i] = reg.predict(x_test)

# Compute the final prediction for each instance in the test set using the average of the predictions for each base regressor
final_predictions = np.mean(list(predictions.values()), axis=0)

mse_score = mean_squared_error(y_test , final_predictions)

evs_score = explained_variance_score(y_test, final_predictions)

mae_score = mean_absolute_error(y_test, final_predictions)

msle_score = mean_squared_log_error(y_test, final_predictions)

r2_s = r2_score(y_test, final_predictions)

time_final = time.time()

print("MSE:", mse_score)
print("EVS:", evs_score)
print("MAE:", mae_score)
print("MSLE:", msle_score)
print("r2:", r2_s)
print("Time:", time_final - time_init)
